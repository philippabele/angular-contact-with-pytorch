Chapter 2: Basics
2.1 Machine Learning Overview
Definition of Machine Learning
Types of Machine Learning
Supervised Learning
Unsupervised Learning
Reinforcement Learning
Typical Workflow in Machine Learning
Use Cases and Applications of Machine Learning
Challenges in Machine Learning
Overfitting and Underfitting
Bias-Variance Tradeoff
Data Quality
Introduction to Neural Networks
Basic Concepts: Neurons, Weights, Activation Functions
Feedforward Neural Networks
Backpropagation Algorithm
2.2 PyTorch Introduction
Introduction to PyTorch
Tensors in PyTorch
Creating Tensors
Operations on Tensors
Autograd: Automatic Differentiation
Building a Simple Neural Network with PyTorch
Defining the Network Architecture
Loss Function and Optimizers
Training the Network
Saving and Loading Models
PyTorch vs Other Deep Learning Libraries (e.g., TensorFlow)
2.3 Understanding Ball Bearings
Introduction to Ball Bearings
Components of Ball Bearings
Functions and Applications of Ball Bearings
Common Parameters and Metrics in Ball Bearing Systems
Fr (Radial Load)
n (Rotational Speed)
Lifetime
Factors Influencing Ball Bearing Performance
Failure Modes of Ball Bearings
Importance of Predicting Ball Bearing Lifetime


\chapter{Basics}
\label{sec:basics}

\section{Machine Learning Overview}

Machine learning is a subfield of \ac{ai} that empowers systems with the ability to automatically learn and improve from experience. Rather than relying on explicit programming, these systems develop programs by using patterns and inferences from data. Machine learning has been one of the most exciting advancements in the field of artificial intelligence and is extensively being used to develop algorithms that can crunch through large data to produce models that can process individual samples. They are particularly good at recognizing patterns which is essential for decision making and predictions.

One of the classic definitions, by Tom Mitchell, succinctly captures the goal of machine learning: ''A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E'' \cite[2]{mitchell1997machine}.

The applications of machine learning are extensive. With the massive amounts of data being generated, there is a need to make better use of it. In business, it is being used for credit fraud detection and customer insights. In healthcare, it is used for identifying trends that could improve diagnoses and patient treatment. And in technology, it can be used to expand the capabilities of AI and continually improve the algorithms used in analytics for apps. It is the driving force behind the innovations that improve efficiencies and affect our day-to-day lives.

Machine learning is particularly good at recognizing patterns and making predictions. This is achieved by processing data and producing a model that can infer from new data. The accuracy of the inference is highly dependent on the quality of data and the algorithm. This is a field that is continuously evolving and is heavily researched.


\subsection{Types of Machine Learning}

Machine learning algorithms can be broadly categorized into three main types based on the nature of the learning signal or feedback available to them during training. The three types are supervised learning, unsupervised learning, and reinforcement learning.

\subsubsection{Supervised Learning}
Supervised learning is a type of machine learning where the algorithm is trained on a labeled dataset. This means that for every input data, there is a corresponding label or output value associated with it. The algorithm makes predictions or decisions based on this input-output mapping which it learns during the training phase. Once the training is complete, the algorithm can be used to predict output values for new, unseen data. Common algorithms used in supervised learning include linear regression for regression problems and support vector machines, and neural networks for classification problems. Some popular applications of supervised learning include predicting house prices based on various features like size and location, and classifying emails as spam or not spam.

\subsubsection{Unsupervised Learning}
Unlike supervised learning, in unsupervised learning, the algorithm is not provided with labeled data. It tries to learn the patterns and the structure from the data. Clustering and association are two common problems solved by unsupervised learning. Clustering involves grouping data into clusters based on similarity. Dimensionality reduction is another area where unsupervised learning excels. By reducing the number of variables or features, it helps in visualizing multidimensional data, noise reduction, and improving the efficiency of other algorithms. Common algorithms in unsupervised learning include k-means for clustering problems and principal component analysis for dimensionality reduction. It is used in market segmentation, anomaly detection, and recommendation systems among others.

\subsubsection{Reinforcement Learning}
Reinforcement learning is a type of machine learning where an agent learns to behave in an environment by performing certain actions and observing the rewards which it gets from those actions. The goal is to learn a policy that maximizes the expected cumulative reward over time. Unlike supervised learning, there is no correct answer or optimal action that the agent is told. It learns through trial and error. Reinforcement learning has been used in various fields like gaming where it has been used to train agents to play and excel at games like Go and Atari, in robotics for autonomous navigation, and in web-based applications for optimizing click-through rates.

\subsection{Typical Workflow in Machine Learning}
Developing a machine learning model is a systematic process that involves a series of steps. Each step is important for ensuring the reliability and performance of the final model. Below is a summary of the typical workflow in machine learning:

\begin{enumerate}
    \item \textbf{Data Collection:} Gather data relevant to the problem domain in various formats such as tables, images, or text. High quality and relevant data is crucial for training effective models.
    
    \item \textbf{Data Preprocessing and Exploratory Data Analysis (EDA):} Clean the data, handle missing values, normalize features, and encode categorical variables through data preprocessing. Perform EDA to examine the data, understand its characteristics and quality through visualization and statistical analysis.
    
    \item \textbf{Data Splitting:} Divide the data into training, validation, and test sets. The model is trained on the training set, hyperparameters are tuned with the validation set, and the model's performance is evaluated on the test set.
    
    \item \textbf{Model Selection and Training:} Select an appropriate machine learning algorithm based on the nature of the problem and characteristics of the data. Train the model using the training dataset, adjusting its internal parameters to minimize errors.
    
    \item \textbf{Model Evaluation:} Evaluate the model's performance on unseen data using metrics such as accuracy, mean squared error, precision, or recall, depending on the nature of the problem.
    
    \item \textbf{Hyperparameter Tuning:} Optimize the model by adjusting its hyperparameters. Common techniques for hyperparameter tuning include:
    \begin{itemize}
        \item \textit{Grid Search}: Systematically evaluate all possible combinations of hyperparameters.
        \item \textit{Random Search}: Randomly sample the space of hyperparameters.
        \item \textit{Bayesian Optimization}: Use probabilistic models to predict the performance of hyperparameters, selecting promising combinations to evaluate.
    \end{itemize}
\end{enumerate}


\subsection{Challenges in Machine Learning}

Machine learning encompasses a wide array of challenges which are inherent in the nature of the algorithms, the data they work with, and the need to make trade-offs among competing aspects of performance. This section highlights three of the most prominent challenges: overfitting and underfitting, the bias-variance tradeoff, and data quality.

\subsubsection{Overfitting and Underfitting}
Overfitting occurs when a machine learning model captures the noise or random fluctuations in the training data, causing the model to perform poorly on unseen data. This happens because the model becomes too complex and starts to fit not just the underlying trends in the data but also the noise. In contrast, underfitting happens when the model does not capture the underlying trends in the data, usually because it is too simple. Addressing overfitting and underfitting typically involves techniques such as cross-validation, regularization, and using the right complexity in the model.

\subsubsection{Bias-Variance Tradeoff}
The bias-variance tradeoff is a fundamental concept that captures the tradeoff between the model's complexity and its ability to generalize to new data. Bias errors occur when the model makes overly simplistic assumptions about the data, and variance errors occur when the model is too sensitive to small fluctuations in the training data. Striking the right balance between bias and variance is crucial for building a model that performs well on new, unseen data.

\subsubsection{Data Quality}
The performance of a machine learning model is heavily dependent on the quality of the data it is trained on. Low-quality data, which can arise from various issues such as missing values, inconsistencies, and noise, can severely hamper the model's ability to make accurate predictions. Data preprocessing, including cleaning and transformation, is essential for improving data quality before training the model. Furthermore, data augmentation is an effective technique to artificially expand the dataset, especially when the amount of training data is limited. It involves creating new data instances through various modifications of the original data, such as adding noise, scaling, or using synthetic data generation techniques like SMOTE for imbalanced datasets.

\subsection{Introduction to Neural Networks}

Neural networks are computational models inspired by the neural structure of the human brain. They are composed of layers of interconnected processing nodes, known as neurons or artificial neurons. Neural networks have been particularly effective in handling complex and non-linear relationships in data, making them suitable for tasks such as image and speech recognition, natural language processing, and game playing.

\subsubsection{Basic Concepts: Neurons, Weights, and Activation Functions}

A neural network consists of layers of interconnected neurons. Each neuron in a layer is connected to neurons in the previous layer through weighted connections. The fundamental components of neural networks are:

\begin{itemize}
    \item \textbf{Neurons:} The basic processing units of the neural network which compute a weighted sum of their inputs and pass it through a non-linear function, known as an activation function.
    
    \item \textbf{Weights:} These are the values that control the strength and direction of the connection between two neurons. Weights are learned and adjusted during the training process.
    
    \item \textbf{Activation Functions:} These functions introduce non-linearities into the network. Common activation functions include the sigmoid, hyperbolic tangent (tanh), and Rectified Linear Unit (ReLU).
\end{itemize}

\subsubsection{Feedforward Neural Networks}

Feedforward neural networks are the simplest type of neural network architecture where the data flows in a single direction from the input layer to the output layer, without any cycles or loops. Each neuron in a layer is connected to every neuron in the previous layer. Feedforward networks are widely used for pattern recognition and are well-suited for mapping input patterns to output patterns.

\subsubsection{Backpropagation Algorithm}

Backpropagation, short for "backward propagation of errors", is a critical algorithm for training neural networks, particularly feedforward neural networks. It is used to minimize the error in the network's predictions by iteratively adjusting the weights and biases. The backpropagation algorithm involves two main phases: the forward pass, where the input is passed through the network to compute the output, and the backward pass, where the gradient of the error with respect to each weight is computed. This gradient information is then used to update the weights in the network to reduce the error.


\section{PyTorch}
\subsection{Tensors}

Tensors are a powerful data structure used in PyTorch to represent and manipulate multi-dimensional arrays.
They are similar to arrays and matrices, but have additional features optimized for use in deep learning applications.
Tensors can be used to represent inputs, outputs, and parameters of a model, and can be run on GPUs or other hardware accelerators for faster processing.
They are designed to support automatic differentiation, a crucial aspect of training deep learning models.
Tensors can be created from data or NumPy arrays and have attributes that describe their shape, datatype, and device location.
With over 100 available tensor operations in PyTorch, including arithmetic, linear algebra, matrix manipulation, and sampling, they provide a flexible and efficient way to perform a wide range of mathematical operations required in deep learning.


\subsection{Datasets \& Dataloaders}

Datasets and data loaders are two important concepts for data processing and model training in PyTorch.
A dataset in PyTorch is an object that holds the data, such as images and labels, that will be used for training or testing a model.
On the other hand, a data loader is an object that can efficiently load data from a dataset and provide a convenient way to iterate over the samples.
PyTorch provides built-in datasets and data loaders for common tasks, such as image classification, text analysis, and audio processing.
Alternatively, one can create custom datasets and data loaders for their own data sources.


\subsection{Transforms}

Transforms are used in machine learning to manipulate data and make it suitable for training.
In PyTorch, all TorchVision datasets have two parameters - transform to modify the features and target\_transform to modify the labels - that accept callables containing the transformation logic.
The torchvision.transforms module offers several commonly used transforms out of the box.


\subsection{Neural Networks}
Neural networks are made up of layers that perform operations on data.
PyTorch provides all the building blocks needed to build a neural network.
Every module in PyTorch subclasses the nn.Module.
A neural network is a module itself that consists of other modules (layers).
This nested structure allows for building and managing complex architectures easily.

To define a neural network, we subclass nn.Module and initialize the neural network layers in init.
Every nn.Module subclass implements the operations on input data in the forward method.

The last linear layer of the neural network returns logits, which are raw values in the range of [-infinity, infinity].
These values are then passed to the nn.Softmax module to produce probabilities, which are scaled to the range of [0, 1].
The dim parameter specifies the dimension along which the values must sum to 1.

Many layers inside a neural network are parameterized, i.e. have associated weights and biases that are optimized during training.
Subclassing nn.Module automatically tracks all fields defined inside your model object, and makes all parameters accessible using your model's parameters() or named\_parameters() methods.


\subsection{Automatic differentiation with torch.autograd}
PyTorch has a built-in differentiation engine called torch.autograd that supports automatic computation of gradient for any computational graph.
It provides classes and functions implementing automatic differentiation of arbitrary scalar valued functions.
It requires minimal changes to the existing code - you only need to declare Tensors for which gradients should be computed with the requires\_grad=True keyword.

In order to optimize weights of parameters in the neural network, we need to compute the derivatives of our loss function with respect to parameters.
To compute those derivatives, we call loss.backward(), and then retrieve the values from w.grad and b.grad.

The backward pass kicks off when .backward() is called on the DAG root. autograd then accumulates them in the respective tensor's .grad attribute using the chain rule, propagates all the way to the leaf tensors.
