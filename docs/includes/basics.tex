Chapter 2: Basics
2.1 Machine Learning Overview
Definition of Machine Learning
Types of Machine Learning
Supervised Learning
Unsupervised Learning
Reinforcement Learning
Typical Workflow in Machine Learning
Use Cases and Applications of Machine Learning
Challenges in Machine Learning
Overfitting and Underfitting
Bias-Variance Tradeoff
Data Quality
Introduction to Neural Networks
Basic Concepts: Neurons, Weights, Activation Functions
Feedforward Neural Networks
Backpropagation Algorithm
2.2 PyTorch Introduction
Introduction to PyTorch
Tensors in PyTorch
Creating Tensors
Operations on Tensors
Autograd: Automatic Differentiation
Building a Simple Neural Network with PyTorch
Defining the Network Architecture
Loss Function and Optimizers
Training the Network
Saving and Loading Models
PyTorch vs Other Deep Learning Libraries (e.g., TensorFlow)
2.3 Understanding Ball Bearings
Introduction to Ball Bearings
Components of Ball Bearings
Functions and Applications of Ball Bearings
Common Parameters and Metrics in Ball Bearing Systems
Fr (Radial Load)
n (Rotational Speed)
Lifetime
Factors Influencing Ball Bearing Performance
Failure Modes of Ball Bearings
Importance of Predicting Ball Bearing Lifetime


\chapter{Basics}
\label{sec:basics}

\section{Machine Learning Overview}

Machine learning is a subfield of \ac{ai} that empowers systems with the ability to automatically learn and improve from experience. Rather than relying on explicit programming, these systems develop programs by using patterns and inferences from data. Machine learning has been one of the most exciting advancements in the field of artificial intelligence and is extensively being used to develop algorithms that can crunch through large data to produce models that can process individual samples. They are particularly good at recognizing patterns which is essential for decision making and predictions.

One of the classic definitions, by Tom Mitchell, succinctly captures the goal of machine learning: ''A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E'' \cite[2]{mitchell1997machine}.

The applications of machine learning are extensive. With the massive amounts of data being generated, there is a need to make better use of it. In business, it is being used for credit fraud detection and customer insights. In healthcare, it is used for identifying trends that could improve diagnoses and patient treatment. And in technology, it can be used to expand the capabilities of AI and continually improve the algorithms used in analytics for apps. It is the driving force behind the innovations that improve efficiencies and affect our day-to-day lives.

Machine learning is particularly good at recognizing patterns and making predictions. This is achieved by processing data and producing a model that can infer from new data. The accuracy of the inference is highly dependent on the quality of data and the algorithm. This is a field that is continuously evolving and is heavily researched.


\subsection{Types of Machine Learning}

Machine learning algorithms can be broadly categorized into three main types based on the nature of the learning signal or feedback available to them during training. The three types are supervised learning, unsupervised learning, and reinforcement learning.

\subsubsection{Supervised Learning}
Supervised learning is a type of machine learning where the algorithm is trained on a labeled dataset. This means that for every input data, there is a corresponding label or output value associated with it. The algorithm makes predictions or decisions based on this input-output mapping which it learns during the training phase. Once the training is complete, the algorithm can be used to predict output values for new, unseen data. Common algorithms used in supervised learning include linear regression for regression problems and support vector machines, and neural networks for classification problems. Some popular applications of supervised learning include predicting house prices based on various features like size and location, and classifying emails as spam or not spam.

\subsubsection{Unsupervised Learning}
Unlike supervised learning, in unsupervised learning, the algorithm is not provided with labeled data. It tries to learn the patterns and the structure from the data. Clustering and association are two common problems solved by unsupervised learning. Clustering involves grouping data into clusters based on similarity. Dimensionality reduction is another area where unsupervised learning excels. By reducing the number of variables or features, it helps in visualizing multidimensional data, noise reduction, and improving the efficiency of other algorithms. Common algorithms in unsupervised learning include k-means for clustering problems and principal component analysis for dimensionality reduction. It is used in market segmentation, anomaly detection, and recommendation systems among others.

\subsubsection{Reinforcement Learning}
Reinforcement learning is a type of machine learning where an agent learns to behave in an environment by performing certain actions and observing the rewards which it gets from those actions. The goal is to learn a policy that maximizes the expected cumulative reward over time. Unlike supervised learning, there is no correct answer or optimal action that the agent is told. It learns through trial and error. Reinforcement learning has been used in various fields like gaming where it has been used to train agents to play and excel at games like Go and Atari, in robotics for autonomous navigation, and in web-based applications for optimizing click-through rates.

\subsection{Typical Workflow in Machine Learning}
Developing a machine learning model is a systematic process that involves a series of steps. Each step is important for ensuring the reliability and performance of the final model. Below is a summary of the typical workflow in machine learning:

\begin{enumerate}
    \item \textbf{Data Collection:} Gather data relevant to the problem domain in various formats such as tables, images, or text. High quality and relevant data is crucial for training effective models.
    
    \item \textbf{Data Preprocessing and Exploratory Data Analysis (EDA):} Clean the data, handle missing values, normalize features, and encode categorical variables through data preprocessing. Perform EDA to examine the data, understand its characteristics and quality through visualization and statistical analysis.
    
    \item \textbf{Data Splitting:} Divide the data into training, validation, and test sets. The model is trained on the training set, hyperparameters are tuned with the validation set, and the model's performance is evaluated on the test set.
    
    \item \textbf{Model Selection and Training:} Select an appropriate machine learning algorithm based on the nature of the problem and characteristics of the data. Train the model using the training dataset, adjusting its internal parameters to minimize errors.
    
    \item \textbf{Model Evaluation:} Evaluate the model's performance on unseen data using metrics such as accuracy, mean squared error, precision, or recall, depending on the nature of the problem.
    
    \item \textbf{Hyperparameter Tuning:} Optimize the model by adjusting its hyperparameters. Common techniques for hyperparameter tuning include:
    \begin{itemize}
        \item \textit{Grid Search}: Systematically evaluate all possible combinations of hyperparameters.
        \item \textit{Random Search}: Randomly sample the space of hyperparameters.
        \item \textit{Bayesian Optimization}: Use probabilistic models to predict the performance of hyperparameters, selecting promising combinations to evaluate.
    \end{itemize}
\end{enumerate}


\subsection{Challenges in Machine Learning}

Machine learning encompasses a wide array of challenges which are inherent in the nature of the algorithms, the data they work with, and the need to make trade-offs among competing aspects of performance. This section highlights three of the most prominent challenges: overfitting and underfitting, the bias-variance tradeoff, and data quality.

\subsubsection{Overfitting and Underfitting}
Overfitting occurs when a machine learning model captures the noise or random fluctuations in the training data, causing the model to perform poorly on unseen data. This happens because the model becomes too complex and starts to fit not just the underlying trends in the data but also the noise. In contrast, underfitting happens when the model does not capture the underlying trends in the data, usually because it is too simple. Addressing overfitting and underfitting typically involves techniques such as cross-validation, regularization, and using the right complexity in the model.

\subsubsection{Bias-Variance Tradeoff}
The bias-variance tradeoff is a fundamental concept that captures the tradeoff between the model's complexity and its ability to generalize to new data. Bias errors occur when the model makes overly simplistic assumptions about the data, and variance errors occur when the model is too sensitive to small fluctuations in the training data. Striking the right balance between bias and variance is crucial for building a model that performs well on new, unseen data.

\subsubsection{Data Quality}
The performance of a machine learning model is heavily dependent on the quality of the data it is trained on. Low-quality data, which can arise from various issues such as missing values, inconsistencies, and noise, can severely hamper the model's ability to make accurate predictions. Data preprocessing, including cleaning and transformation, is essential for improving data quality before training the model. Furthermore, data augmentation is an effective technique to artificially expand the dataset, especially when the amount of training data is limited. It involves creating new data instances through various modifications of the original data, such as adding noise, scaling, or using synthetic data generation techniques like SMOTE for imbalanced datasets.

\subsection{Introduction to Neural Networks}

Neural networks are computational models inspired by the neural structure of the human brain. They are composed of layers of interconnected processing nodes, known as neurons or artificial neurons. Neural networks have been particularly effective in handling complex and non-linear relationships in data, making them suitable for tasks such as image and speech recognition, natural language processing, and game playing.

\subsubsection{Basic Concepts: Neurons, Weights, and Activation Functions}

A neural network consists of layers of interconnected neurons. Each neuron in a layer is connected to neurons in the previous layer through weighted connections. The fundamental components of neural networks are:

\begin{itemize}
    \item \textbf{Neurons:} The basic processing units of the neural network which compute a weighted sum of their inputs and pass it through a non-linear function, known as an activation function.
    
    \item \textbf{Weights:} These are the values that control the strength and direction of the connection between two neurons. Weights are learned and adjusted during the training process.
    
    \item \textbf{Activation Functions:} These functions introduce non-linearities into the network. Common activation functions include the sigmoid, hyperbolic tangent (tanh), and Rectified Linear Unit (ReLU).
\end{itemize}

\subsubsection{Feedforward Neural Networks}

Feedforward neural networks are the simplest type of neural network architecture where the data flows in a single direction from the input layer to the output layer, without any cycles or loops. Each neuron in a layer is connected to every neuron in the previous layer. Feedforward networks are widely used for pattern recognition and are well-suited for mapping input patterns to output patterns.

\subsubsection{Backpropagation Algorithm}

Backpropagation, short for "backward propagation of errors", is a critical algorithm for training neural networks, particularly feedforward neural networks. It is used to minimize the error in the network's predictions by iteratively adjusting the weights and biases. The backpropagation algorithm involves two main phases: the forward pass, where the input is passed through the network to compute the output, and the backward pass, where the gradient of the error with respect to each weight is computed. This gradient information is then used to update the weights in the network to reduce the error.


\section{PyTorch Introduction}

PyTorch is an open-source deep learning library developed by Facebook's AI Research lab. It is popular among researchers and developers due to its ease of use, flexibility, and efficient memory usage. PyTorch facilitates the development of deep learning models with its rich set of modules and functionalities. Additionally, PyTorch supports GPU acceleration which can significantly increase the speed of computationally intensive tasks in deep learning.

\subsection{Tensors in PyTorch}

Tensors are the fundamental data structures in PyTorch, which generalize the concept of scalars, vectors, and matrices to an arbitrary number of dimensions. They play an important role in building and training deep learning models, as they represent inputs, outputs, and parameters. PyTorch tensors are optimized for GPU processing, which is highly beneficial for computationally intensive tasks.

Creating tensors can be done in multiple ways, such as converting from data like lists or NumPy arrays, or by initializing empty tensors of specific sizes and data types. Furthermore, PyTorch boasts a comprehensive set of operations to manipulate tensors, encompassing arithmetic, linear algebra, matrix manipulation, and sampling, among others. These operations are fundamental for the mathematical computations required in deep learning.

\subsection{Datasets and Dataloaders}

Datasets and data loaders are crucial components in data processing and model training in PyTorch. A dataset in PyTorch is an object that contains the data, such as images and labels, which are used for training or testing a model. Dataloaders, on the other hand, efficiently load data from a dataset and offer an easy way to iterate over samples, which is especially helpful for large datasets.

PyTorch provides built-in datasets and data loaders for common tasks like image classification, text analysis, and audio processing. Moreover, users can create custom datasets and data loaders for specific data sources.

\subsection{Transforms}

Data transformation is often necessary to condition the data into a suitable form for training deep learning models. PyTorch's `torchvision.transforms` module provides several common transforms out of the box. Additionally, all TorchVision datasets have two parameters - `transform` to modify the features and `target\_transform` to modify the labels - that accept callables containing the transformation logic.

\subsection{Building a Neural Network with PyTorch}

PyTorch offers all the building blocks necessary to construct a neural network. Neural networks are made of layers that perform operations on data. In PyTorch, every module subclasses the `nn.Module`. A neural network is itself a module that comprises other modules (layers). 

To define a neural network in PyTorch, one needs to subclass `nn.Module` and initialize the neural network layers in the constructor. The `forward` method is then implemented, which conducts operations on input data.

Neural networks often have parameterized layers, meaning they have associated weights and biases that are optimized during training. These parameters are automatically tracked when a model object subclasses `nn.Module`.

The last linear layer of a neural network usually returns logits, which are raw values ranging from negative infinity to infinity. These logits are then fed through a softmax function to produce probabilities that sum to 1 across specified dimensions.

\subsection{Automatic Differentiation with torch.autograd}

PyTorch provides a built-in differentiation engine called `torch.autograd`. It supports automatic computation of gradients for any computational graph. It is a powerful tool that eases the computation of gradients for neural networks, which is essential for the optimization of the weights.

In practice, you only need to declare which tensors you want gradients for by setting `requires\_grad=True`. After computing the loss, calling `loss.backward()` will compute the gradients for all tensors with `requires\_grad=True`. These gradients are accumulated in the `.grad` attribute of the respective tensors.

\subsection{Training the Network}

Training a neural network involves iterating over the training data, and for each batch, performing forward and backward passes through the network, computing the loss and updating the weights using an optimization algorithm such as Stochastic Gradient Descent (SGD).

During training, the data is passed through the network (forward pass), and a loss is calculated reflecting how far the network's output is from the ground truth. The gradients of this loss with respect to the network's weights are computed, and the optimizer uses these gradients to update the weights (backward pass).

\subsection{Saving and Loading Models}

Once a model has been trained, it is possible to save its parameters to a file. This is useful for reusing models, sharing them, or deploying them in production environments. In PyTorch, you can use `torch.save()` to save a model's state dictionary, and `torch.load()` to load the state dictionary into a model's architecture.

This process allows for the preservation and later restoration of models, facilitating continuity in research and development, as well as the deployment of machine learning models into production environments.
